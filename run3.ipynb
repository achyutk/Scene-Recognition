{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "06fff7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, top_k_accuracy_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a560344b",
   "metadata": {},
   "source": [
    "## 1. Initiate varibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7dab7878",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 200 # number of representative vectors\n",
    "feature_type = 'spatial_pyramid' \n",
    "# ['dense_sift', 'pyramid_dense_sift', 'spatial_pyramid', \n",
    "#  'dense_orb', 'spatial_pyramid_orb',\n",
    "#  'dense_brief', 'spatial_pyramid_brief']\n",
    "sift_step_size = 5\n",
    "num_level = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e99ecc2",
   "metadata": {},
   "source": [
    "## 2. Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "41c94333",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'img_path': [], 'label': []}\n",
    "\n",
    "for root, dirs, files in os.walk(\"./training/\"):\n",
    "    label = os.path.basename(root)\n",
    "    for file in files:\n",
    "        if file.endswith('.jpg'):\n",
    "            data['img_path'].append(os.path.join(root, file))\n",
    "            data['label'].append(label)\n",
    "\n",
    "df_data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a72289ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./training/Forest/63.jpg</td>\n",
       "      <td>Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./training/Forest/77.jpg</td>\n",
       "      <td>Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./training/Forest/88.jpg</td>\n",
       "      <td>Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./training/Forest/89.jpg</td>\n",
       "      <td>Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./training/Forest/76.jpg</td>\n",
       "      <td>Forest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   img_path   label\n",
       "0  ./training/Forest/63.jpg  Forest\n",
       "1  ./training/Forest/77.jpg  Forest\n",
       "2  ./training/Forest/88.jpg  Forest\n",
       "3  ./training/Forest/89.jpg  Forest\n",
       "4  ./training/Forest/76.jpg  Forest"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65737fb1",
   "metadata": {},
   "source": [
    "## 3. Feature Extraction and Bag of visual words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8e4d57cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_words = []\n",
    "\n",
    "for i, row in df_data.iterrows():\n",
    "    # read image from img_path then convert to gray scale\n",
    "    image = cv2.imread(row['img_path'])\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # get descriptors for each image\n",
    "    if feature_type in ['dense_sift', 'pyramid_dense_sift', 'spatial_pyramid']:\n",
    "        visual_words.append(utils.dense_sift(image, sift_step_size))\n",
    "    elif feature_type in ['dense_orb', 'spatial_pyramid_orb']:\n",
    "        visual_words.append(utils.dense_orb(image, sift_step_size))\n",
    "    elif feature_type in ['dense_brief', 'spatial_pyramid_brief']:\n",
    "        visual_words.append(utils.dense_brief(image, sift_step_size))\n",
    "    elif feature_type == 'dense_surf':\n",
    "        visual_words.append(dense_surf(image, sift_step_size))\n",
    "\n",
    "df_data['visual_words'] = visual_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4fd66951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>label</th>\n",
       "      <th>visual_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./training/Forest/63.jpg</td>\n",
       "      <td>Forest</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./training/Forest/77.jpg</td>\n",
       "      <td>Forest</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./training/Forest/88.jpg</td>\n",
       "      <td>Forest</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./training/Forest/89.jpg</td>\n",
       "      <td>Forest</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./training/Forest/76.jpg</td>\n",
       "      <td>Forest</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   img_path   label  \\\n",
       "0  ./training/Forest/63.jpg  Forest   \n",
       "1  ./training/Forest/77.jpg  Forest   \n",
       "2  ./training/Forest/88.jpg  Forest   \n",
       "3  ./training/Forest/89.jpg  Forest   \n",
       "4  ./training/Forest/76.jpg  Forest   \n",
       "\n",
       "                                        visual_words  \n",
       "0  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "1  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "2  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "3  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "4  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689997e3",
   "metadata": {},
   "source": [
    "### Create representation vectors - codebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b1878f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag of visual words size: (4060424, 128)\n"
     ]
    }
   ],
   "source": [
    "# preparing bag of visual words\n",
    "BoVW = df_data['visual_words'].to_list()\n",
    "BoVW = np.vstack(BoVW)\n",
    "\n",
    "print('bag of visual words size:', BoVW.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3ad09056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Means clustering\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "flags = cv2.KMEANS_RANDOM_CENTERS\n",
    "compactness, labels, centres = cv2.kmeans(BoVW, k, None, criteria, 10, flags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca992559",
   "metadata": {},
   "source": [
    "### Histograms of bags of visual words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "72f64c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spatial_pyramid\n"
     ]
    }
   ],
   "source": [
    "his_bovw = []\n",
    "print(feature_type)\n",
    "\n",
    "for i, row in df_data.iterrows():\n",
    "    # read image from img_path then convert to gray scale\n",
    "    image = cv2.imread(row['img_path'])\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # dense SIFT\n",
    "    if feature_type == 'dense_sift':\n",
    "        his_bovw.append(utils.histogram_bovw(utils.dense_sift(image, sift_step_size), \n",
    "                                       centres, k))\n",
    "    \n",
    "    # pyramid dense SIFT\n",
    "    elif feature_type == 'pyramid_dense_sift':\n",
    "        his_bovw.append(utils.histogram_bovw(utils.pyramid_dense_sift(image, sift_step_size, \n",
    "                                                          num_level), centres, k))\n",
    "    # dense SIFT with spatial pooling    \n",
    "    elif feature_type == 'spatial_pyramid':\n",
    "        his_bovw.append(utils.spatial_pyramid(image, centres, k, sift_step_size, num_level))\n",
    "        \n",
    "    # dense ORB\n",
    "    elif feature_type == 'dense_orb':\n",
    "        his_bovw.append(utils.histogram_bovw(utils.dense_orb(image, sift_step_size), \n",
    "                                       centres, k))\n",
    "    \n",
    "    # dense ORB with spatial pooling  \n",
    "    elif feature_type == 'spatial_pyramid_orb':\n",
    "        his_bovw.append(utils.spatial_pyramid_orb(image, centres, k, sift_step_size, num_level))\n",
    "    \n",
    "    # dense BRIEF \n",
    "    elif feature_type == 'dense_brief':\n",
    "        his_bovw.append(utils.histogram_bovw(utils.dense_brief(image, sift_step_size), \n",
    "                                       centres, k))\n",
    "    \n",
    "    # dense BRIEF with spatial pooling  \n",
    "    elif feature_type == 'spatial_pyramid_brief':\n",
    "        his_bovw.append(utils.spatial_pyramid_brief(image, centres, k, sift_step_size, num_level))\n",
    "\n",
    "his_bovw = np.array(his_bovw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7f330eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 1000)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "his_bovw = np.array(his_bovw)\n",
    "his_bovw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb64833",
   "metadata": {},
   "source": [
    "## 4. Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "6202a79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 1000) (1500,)\n"
     ]
    }
   ],
   "source": [
    "X = his_bovw\n",
    "y = np.array(df_data['label'].to_list())\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fff2e83",
   "metadata": {},
   "source": [
    "### Train - Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "e9c9875c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
    "\n",
    "# normalizing\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_norm = scaler.transform(X_train)\n",
    "X_test_norm = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1381d15a",
   "metadata": {},
   "source": [
    "### SVC (kernel: rbf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "4f8d9652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7033333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Coast       0.80      0.70      0.74        23\n",
      "      Forest       0.90      0.86      0.88        21\n",
      "     Highway       0.91      0.74      0.82        27\n",
      "  Insidecity       0.68      0.83      0.75        18\n",
      "    Mountain       0.70      0.78      0.74        18\n",
      "      Office       0.70      0.84      0.76        19\n",
      " OpenCountry       0.48      0.67      0.56        15\n",
      "      Street       0.88      0.84      0.86        25\n",
      "      Suburb       0.91      1.00      0.95        21\n",
      "TallBuilding       0.84      0.94      0.89        17\n",
      "     bedroom       0.44      0.33      0.38        21\n",
      "  industrial       0.67      0.56      0.61        18\n",
      "     kitchen       0.36      0.38      0.37        21\n",
      "  livingroom       0.40      0.29      0.33        21\n",
      "       store       0.72      0.87      0.79        15\n",
      "\n",
      "    accuracy                           0.70       300\n",
      "   macro avg       0.69      0.71      0.69       300\n",
      "weighted avg       0.70      0.70      0.70       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(probability=True).fit(X_train_norm, y_train)\n",
    "y_pred = clf.predict(X_test_norm)\n",
    "print('accuracy:', accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "0772dd73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16,  0,  2,  0,  0,  0,  5,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0, 18,  0,  0,  0,  0,  1,  1,  0,  1,  0,  0,  0,  0,  0],\n",
       "       [ 2,  0, 20,  1,  2,  0,  2,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0, 15,  1,  0,  0,  1,  0,  1,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0, 14,  0,  3,  0,  0,  1,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  1,  0, 16,  0,  0,  0,  0,  1,  0,  1,  0,  0],\n",
       "       [ 2,  1,  0,  0,  2,  0, 10,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  1,  0,  3,  0,  0,  0, 21,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0, 21,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  1,  0,  0,  0,  0, 16,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  7,  1,  7,  4,  1],\n",
       "       [ 0,  0,  0,  0,  0,  1,  0,  0,  2,  0,  1, 10,  0,  2,  2],\n",
       "       [ 0,  0,  0,  0,  0,  4,  0,  1,  0,  0,  4,  1,  8,  3,  0],\n",
       "       [ 0,  0,  0,  2,  0,  1,  0,  0,  0,  0,  3,  2,  5,  6,  2],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  0, 13]])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cccc52",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "4ce7aec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.5766666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Coast       0.78      0.61      0.68        23\n",
      "      Forest       0.88      0.67      0.76        21\n",
      "     Highway       0.79      0.70      0.75        27\n",
      "  Insidecity       0.57      0.72      0.63        18\n",
      "    Mountain       0.40      0.44      0.42        18\n",
      "      Office       0.43      0.53      0.48        19\n",
      " OpenCountry       0.36      0.27      0.31        15\n",
      "      Street       0.67      0.72      0.69        25\n",
      "      Suburb       1.00      0.90      0.95        21\n",
      "TallBuilding       0.56      0.59      0.57        17\n",
      "     bedroom       0.36      0.24      0.29        21\n",
      "  industrial       0.39      0.39      0.39        18\n",
      "     kitchen       0.31      0.43      0.36        21\n",
      "  livingroom       0.55      0.57      0.56        21\n",
      "       store       0.61      0.73      0.67        15\n",
      "\n",
      "    accuracy                           0.58       300\n",
      "   macro avg       0.58      0.57      0.57       300\n",
      "weighted avg       0.59      0.58      0.58       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clf = MultinomialNB().fit(X_train, y_train)\n",
    "clf = GaussianNB().fit(X_train, y_train)\n",
    "# clf = BernoulliNB().fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print('accuracy:', accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e566928",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "7b5cb6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Coast       0.75      0.65      0.70        23\n",
      "      Forest       0.82      0.86      0.84        21\n",
      "     Highway       0.88      0.78      0.82        27\n",
      "  Insidecity       0.62      0.72      0.67        18\n",
      "    Mountain       0.81      0.72      0.76        18\n",
      "      Office       0.68      0.79      0.73        19\n",
      " OpenCountry       0.45      0.60      0.51        15\n",
      "      Street       0.86      0.76      0.81        25\n",
      "      Suburb       0.88      1.00      0.93        21\n",
      "TallBuilding       0.62      0.94      0.74        17\n",
      "     bedroom       0.42      0.38      0.40        21\n",
      "  industrial       0.61      0.61      0.61        18\n",
      "     kitchen       0.41      0.43      0.42        21\n",
      "  livingroom       0.50      0.24      0.32        21\n",
      "       store       0.57      0.53      0.55        15\n",
      "\n",
      "    accuracy                           0.67       300\n",
      "   macro avg       0.66      0.67      0.66       300\n",
      "weighted avg       0.67      0.67      0.66       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier().fit(X_train_norm, y_train)\n",
    "y_pred = clf.predict(X_test_norm)\n",
    "print('accuracy:', accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "12a0e2a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top k accuracy\n",
    "top_k_accuracy_score(y_test, clf.predict_proba(X_test_norm), k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc71d919",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fd5f0c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7025"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'kernel':['rbf'], 'C':np.linspace(1, 10, 50), 'gamma': [0.1, 1.0, 10, 100]}\n",
    "grid_search = GridSearchCV(SVC(), parameters)\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "220369b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 3.061918367346939, 'gamma': 100, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d15cb98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7033333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Coast       0.70      0.70      0.70        23\n",
      "      Forest       0.90      0.86      0.88        21\n",
      "     Highway       0.83      0.74      0.78        27\n",
      "  Insidecity       0.71      0.83      0.77        18\n",
      "    Mountain       0.74      0.78      0.76        18\n",
      "      Office       0.65      0.68      0.67        19\n",
      " OpenCountry       0.53      0.67      0.59        15\n",
      "      Street       0.91      0.84      0.87        25\n",
      "      Suburb       0.95      1.00      0.98        21\n",
      "TallBuilding       0.75      0.88      0.81        17\n",
      "     bedroom       0.44      0.38      0.41        21\n",
      "  industrial       0.88      0.39      0.54        18\n",
      "     kitchen       0.43      0.43      0.43        21\n",
      "  livingroom       0.44      0.52      0.48        21\n",
      "       store       0.76      0.87      0.81        15\n",
      "\n",
      "    accuracy                           0.70       300\n",
      "   macro avg       0.71      0.70      0.70       300\n",
      "weighted avg       0.71      0.70      0.70       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid_search.predict(X_test)\n",
    "print('accuracy:', accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98d766d",
   "metadata": {},
   "source": [
    "## 5. Making predicitions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "962c4ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "test_file_name = []\n",
    "\n",
    "for root, dirs, files in os.walk(\"./testing/\"):\n",
    "    for file in files:\n",
    "        if file.endswith('.jpg'):\n",
    "            test_file_name.append(file)\n",
    "            \n",
    "            img_path = os.path.join(root, file)\n",
    "            # read image from img_path then convert to gray scale\n",
    "            image = cv2.imread(img_path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            test_data.append(utils.spatial_pyramid(image, centres, k, sift_step_size, num_level))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "a430a451",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X.copy()\n",
    "X_test = np.array(test_data)\n",
    "y_train = y.copy()\n",
    "\n",
    "# normalizing\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_norm = scaler.transform(X_train)\n",
    "X_test_norm = scaler.transform(X_test)\n",
    "\n",
    "clf = SVC(probability=True, C=2.2).fit(X_train_norm, y_train)\n",
    "y_pred = clf.predict(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "d03457d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "#Storing predictions in a datframe for testing dataset\n",
    "lists = [m + \" \" + n for m, n in zip(test_file_name, y_pred)]\n",
    "re = pd.DataFrame(lists, columns=['Name'])\n",
    "re['Num'] = [int(x.split('.')[0]) for x in re['Name']]\n",
    "re = re.sort_values(by=['Num'])\n",
    "re = re.reset_index()\n",
    "sub = list(re['Name'])\n",
    "\n",
    "with open(r'run3.txt', 'w') as fp:\n",
    "    for item in sub:\n",
    "        # write each item on a new line\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "    print('Done')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
